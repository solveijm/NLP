{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import pickle\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from collections import OrderedDict\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "def save_response_content(response, destination):\n",
    "    CHUNK_SIZE = 32768\n",
    "\n",
    "    with open(destination, \"wb\") as f:\n",
    "        for chunk in response.iter_content(CHUNK_SIZE):\n",
    "            if chunk: # filter out keep-alive new chunks\n",
    "                f.write(chunk)\n",
    "\n",
    "def download_data(data_path):\n",
    "    toy_data_path = os.path.join(data_path, 'fever_data.zip')\n",
    "    toy_data_url_id = \"1wArZhF9_SHW17WKNGeLmX-QTYw9Zscl1\"\n",
    "    toy_url = \"https://docs.google.com/uc?export=download\"\n",
    "\n",
    "    if not os.path.exists(data_path):\n",
    "        os.makedirs(data_path)\n",
    "\n",
    "    if not os.path.exists(toy_data_path):\n",
    "        print(\"Downloading FEVER data splits...\")\n",
    "        with requests.Session() as current_session:\n",
    "            response = current_session.get(toy_url,\n",
    "                                   params={'id': toy_data_url_id},\n",
    "                                   stream=True)\n",
    "        save_response_content(response, toy_data_path)\n",
    "        print(\"Download completed!\")\n",
    "\n",
    "        print(\"Extracting dataset...\")\n",
    "        with zipfile.ZipFile(toy_data_path) as loaded_zip:\n",
    "            loaded_zip.extractall(data_path)\n",
    "        print(\"Extraction completed!\")\n",
    "\n",
    "# Uncomment if you neewd to dowload the dataset\n",
    "#download_data('dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove this\n",
    "df = pd.DataFrame([{\n",
    "            \"claim_id\": 1,\n",
    "            \"claim\": [\"hello\", \"hi\", \"super\"],\n",
    "            \"evidence\": [\"tagg\", \"same\"]\n",
    "        }])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts(df[\"claim\"])\n",
    "tokenizer.fit_on_texts(df[\"evidence\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hello': 1, 'hi': 2, 'super': 3, 'tagg': 4, 'same': 5}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "claim_train = tokenizer.texts_to_sequences(df[\"claim\"])\n",
    "evidence_train = tokenizer.texts_to_sequences(df[\"evidence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
