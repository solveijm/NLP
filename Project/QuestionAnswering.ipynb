{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "538e1dc1",
   "metadata": {},
   "source": [
    "## Questing Answering on SQuAD dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75a0f04",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60f4b439",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281664e0",
   "metadata": {},
   "source": [
    "## Dataprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac96bfb",
   "metadata": {},
   "source": [
    "#### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c7bf748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(filename=\"training_set.json\", folder=\"SQUAD MATERIAL\"):    \n",
    "    dataset_folder = os.path.join(os.getcwd(), folder)\n",
    "    dataset_path = os.path.join(dataset_folder, filename)\n",
    "    with open(dataset_path) as f:\n",
    "        raw_json = json.load(f)\n",
    "\n",
    "    return raw_json['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8817a293",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b42106",
   "metadata": {},
   "source": [
    "#### Split dataset into train, val and test sets.\n",
    "Splitting on title, so that all answers and questions in one title are in the same dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "03796a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(data):\n",
    "    random.shuffle(data)\n",
    "    length_of_dataset = len(data)\n",
    "    train_split = round(0.8*length_of_dataset)\n",
    "    val_split = train_split + round(0.1*length_of_dataset)\n",
    "    train_data = data[:train_split]\n",
    "    val_data = data[train_split:val_split]\n",
    "    test_data = data[val_split:]\n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1b9e36b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = split_dataset(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b38edc2",
   "metadata": {},
   "source": [
    "#### Create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d350502e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(data):\n",
    "    contexts = []\n",
    "    questions = []\n",
    "    answers_text = []\n",
    "    answers_start = []\n",
    "    question_ids = []\n",
    "    for i in range(len(data)):\n",
    "        paragraphs = data[i]['paragraphs']\n",
    "        for sub_para in paragraphs:\n",
    "            for q_a in sub_para['qas']:\n",
    "                questions.append(q_a['question'])\n",
    "                q_a_answer_starts = []\n",
    "                q_a_answers = []\n",
    "                if len(q_a['answers'])>1:\n",
    "                        print(q_a['answers'])\n",
    "                for answer in q_a['answers']:\n",
    "                    q_a_answer_starts.append(answer['answer_start'])\n",
    "                    q_a_answers.append(answer['text'])\n",
    "                answers_start.append(q_a_answer_starts)\n",
    "                answers_text.append(q_a_answers)\n",
    "                question_ids.append(q_a['id'])\n",
    "                contexts.append(sub_para['context'])   \n",
    "    df = pd.DataFrame({\"questionID\":question_ids, \"context\":contexts, \"question\": questions, \"answer_start\": answers_start, \"text\": answers_text})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cbf2971f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = create_dataframe(train_data)\n",
    "df_val = create_dataframe(val_data)\n",
    "df_test = create_dataframe(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21fd72d",
   "metadata": {},
   "source": [
    "#### Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae2f69a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd709782",
   "metadata": {},
   "source": [
    "#### Make tokenixer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbe7e18",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0917fc4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
