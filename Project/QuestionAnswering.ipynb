{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "538e1dc1",
   "metadata": {},
   "source": [
    "## Questing Answering on SQuAD dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75a0f04",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60f4b439",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "\n",
    "import re\n",
    "from functools import reduce\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from typing import List, Callable, Dict\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from datetime import datetime\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers import Concatenate, Lambda, LSTM, Reshape, Dense, Embedding, Average, Reshape, Flatten, Input, Add, Bidirectional, TimeDistributed, Softmax\n",
    "from keras.models import Model \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras.layers import Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281664e0",
   "metadata": {},
   "source": [
    "## Data pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac96bfb",
   "metadata": {},
   "source": [
    "#### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0f4a366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment for google collab\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0828ab57",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"SQUAD MATERIAL\"\n",
    "#folder = \"drive/MyDrive/NLP_data/SQUAD MATERIAL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c7bf748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(filename=\"training_set.json\", folder=folder):    \n",
    "    dataset_folder = os.path.join(os.getcwd(), folder)\n",
    "    dataset_path = os.path.join(dataset_folder, filename)\n",
    "    with open(dataset_path) as f:\n",
    "        raw_json = json.load(f)\n",
    "\n",
    "    return raw_json['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8817a293",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b42106",
   "metadata": {},
   "source": [
    "#### Split dataset into train, val and test sets.\n",
    "Splitting on title, so that all answers and questions in one title are in the same dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03796a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(data):\n",
    "    random.shuffle(data)\n",
    "    length_of_dataset = len(data)\n",
    "    train_split = round(0.8*length_of_dataset)\n",
    "    val_split = train_split + round(0.1*length_of_dataset)\n",
    "    train_data = data[:train_split]\n",
    "    val_data = data[train_split:val_split]\n",
    "    test_data = data[val_split:]\n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b9e36b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = split_dataset(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b38edc2",
   "metadata": {},
   "source": [
    "#### Create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae626891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_word_index(char_idx, context):\n",
    "    return context[0:char_idx].count(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d350502e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(data):\n",
    "    contexts = []\n",
    "    questions = []\n",
    "    answers_text = []\n",
    "    answers_start = []\n",
    "    answers_end = []\n",
    "    question_ids = []\n",
    "    answers_word_start = []\n",
    "    answers_word_end = []\n",
    "    for i in range(len(data)):\n",
    "        paragraphs = data[i]['paragraphs']\n",
    "        for sub_para in paragraphs:\n",
    "            for q_a in sub_para['qas']:\n",
    "                questions.append(q_a['question'])\n",
    "                q_a_answer_starts = []\n",
    "                q_a_answer_ends = []\n",
    "                q_a_answers = []\n",
    "                q_a_ans_word_idx_start = []\n",
    "                q_a_ans_word_idx_end = []\n",
    "\n",
    "                for answer in q_a['answers']:\n",
    "                    answer_end = answer['answer_start'] + len(answer['text'])\n",
    "                    q_a_answer_starts.append(answer['answer_start'])\n",
    "                    q_a_answer_ends.append(answer_end)\n",
    "                    q_a_answers.append(answer['text'])\n",
    "                    q_a_ans_word_idx_start.append(find_word_index(answer['answer_start'], sub_para['context']))\n",
    "                    q_a_ans_word_idx_end.append(find_word_index(answer_end, sub_para['context']))\n",
    "                    \n",
    "                answers_start.append(q_a_answer_starts)\n",
    "                answers_end.append(q_a_answer_ends)\n",
    "                answers_word_start.append(q_a_ans_word_idx_start)                \n",
    "                answers_word_end.append(q_a_ans_word_idx_end)\n",
    "                answers_text.append(q_a_answers)\n",
    "                question_ids.append(q_a['id'])\n",
    "                contexts.append(sub_para['context'])   \n",
    "    df = pd.DataFrame({\"questionID\":question_ids, \"context\":contexts, \"question\": questions, \"answer_start\": answers_start, \"answer_word_start\": answers_word_start, \"answer_end\": answers_end, \"answer_word_end\": answers_word_end, \"answer_text\": answers_text})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbf2971f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = create_dataframe(train_data)\n",
    "val_df = create_dataframe(val_data)\n",
    "test_df = create_dataframe(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd2d926d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questionID</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_word_start</th>\n",
       "      <th>answer_end</th>\n",
       "      <th>answer_word_end</th>\n",
       "      <th>answer_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5732977f0342181400a20283</td>\n",
       "      <td>A police force is a constituted body of person...</td>\n",
       "      <td>What does the state want a police force to do?</td>\n",
       "      <td>[74]</td>\n",
       "      <td>[14]</td>\n",
       "      <td>[133]</td>\n",
       "      <td>[22]</td>\n",
       "      <td>[enforce the law, protect property, and limit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5732977f0342181400a20284</td>\n",
       "      <td>A police force is a constituted body of person...</td>\n",
       "      <td>What are gendarmerie?</td>\n",
       "      <td>[567]</td>\n",
       "      <td>[90]</td>\n",
       "      <td>[609]</td>\n",
       "      <td>[95]</td>\n",
       "      <td>[military units charged with civil policing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5732977f0342181400a20285</td>\n",
       "      <td>A police force is a constituted body of person...</td>\n",
       "      <td>What are police usually separate from?</td>\n",
       "      <td>[445]</td>\n",
       "      <td>[73]</td>\n",
       "      <td>[540]</td>\n",
       "      <td>[86]</td>\n",
       "      <td>[military or other organizations involved in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>573297e560535514009162f8</td>\n",
       "      <td>Law enforcement, however, constitutes only par...</td>\n",
       "      <td>How are police usually paid?</td>\n",
       "      <td>[535]</td>\n",
       "      <td>[83]</td>\n",
       "      <td>[548]</td>\n",
       "      <td>[84]</td>\n",
       "      <td>[through taxes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>573297e560535514009162fa</td>\n",
       "      <td>Law enforcement, however, constitutes only par...</td>\n",
       "      <td>When were police used to protect the class sys...</td>\n",
       "      <td>[237]</td>\n",
       "      <td>[35]</td>\n",
       "      <td>[271]</td>\n",
       "      <td>[40]</td>\n",
       "      <td>[late 18th and early 19th centuries]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70838</th>\n",
       "      <td>57279954708984140094e1e7</td>\n",
       "      <td>Instead of being defined by \"non\" words, some ...</td>\n",
       "      <td>What type of language has it been suggested th...</td>\n",
       "      <td>[28]</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[39]</td>\n",
       "      <td>[6]</td>\n",
       "      <td>[\"non\" words]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70839</th>\n",
       "      <td>57279954708984140094e1e8</td>\n",
       "      <td>Instead of being defined by \"non\" words, some ...</td>\n",
       "      <td>What type of language are organizations being ...</td>\n",
       "      <td>[75]</td>\n",
       "      <td>[11]</td>\n",
       "      <td>[109]</td>\n",
       "      <td>[13]</td>\n",
       "      <td>[new, positive-sounding terminology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70840</th>\n",
       "      <td>57279954708984140094e1e9</td>\n",
       "      <td>Instead of being defined by \"non\" words, some ...</td>\n",
       "      <td>What is a new term for NPOs that has started t...</td>\n",
       "      <td>[144]</td>\n",
       "      <td>[20]</td>\n",
       "      <td>[170]</td>\n",
       "      <td>[22]</td>\n",
       "      <td>[civil society organization]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70841</th>\n",
       "      <td>57279954708984140094e1ea</td>\n",
       "      <td>Instead of being defined by \"non\" words, some ...</td>\n",
       "      <td>What is a term being used for organizations th...</td>\n",
       "      <td>[295]</td>\n",
       "      <td>[45]</td>\n",
       "      <td>[322]</td>\n",
       "      <td>[47]</td>\n",
       "      <td>[citizen sector organization]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70842</th>\n",
       "      <td>57279954708984140094e1eb</td>\n",
       "      <td>Instead of being defined by \"non\" words, some ...</td>\n",
       "      <td>What would a group like Crowdfund, GoFundMe or...</td>\n",
       "      <td>[507]</td>\n",
       "      <td>[79]</td>\n",
       "      <td>[534]</td>\n",
       "      <td>[81]</td>\n",
       "      <td>[Social Benefit Organization]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70843 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     questionID  \\\n",
       "0      5732977f0342181400a20283   \n",
       "1      5732977f0342181400a20284   \n",
       "2      5732977f0342181400a20285   \n",
       "3      573297e560535514009162f8   \n",
       "4      573297e560535514009162fa   \n",
       "...                         ...   \n",
       "70838  57279954708984140094e1e7   \n",
       "70839  57279954708984140094e1e8   \n",
       "70840  57279954708984140094e1e9   \n",
       "70841  57279954708984140094e1ea   \n",
       "70842  57279954708984140094e1eb   \n",
       "\n",
       "                                                 context  \\\n",
       "0      A police force is a constituted body of person...   \n",
       "1      A police force is a constituted body of person...   \n",
       "2      A police force is a constituted body of person...   \n",
       "3      Law enforcement, however, constitutes only par...   \n",
       "4      Law enforcement, however, constitutes only par...   \n",
       "...                                                  ...   \n",
       "70838  Instead of being defined by \"non\" words, some ...   \n",
       "70839  Instead of being defined by \"non\" words, some ...   \n",
       "70840  Instead of being defined by \"non\" words, some ...   \n",
       "70841  Instead of being defined by \"non\" words, some ...   \n",
       "70842  Instead of being defined by \"non\" words, some ...   \n",
       "\n",
       "                                                question answer_start  \\\n",
       "0         What does the state want a police force to do?         [74]   \n",
       "1                                  What are gendarmerie?        [567]   \n",
       "2                 What are police usually separate from?        [445]   \n",
       "3                           How are police usually paid?        [535]   \n",
       "4      When were police used to protect the class sys...        [237]   \n",
       "...                                                  ...          ...   \n",
       "70838  What type of language has it been suggested th...         [28]   \n",
       "70839  What type of language are organizations being ...         [75]   \n",
       "70840  What is a new term for NPOs that has started t...        [144]   \n",
       "70841  What is a term being used for organizations th...        [295]   \n",
       "70842  What would a group like Crowdfund, GoFundMe or...        [507]   \n",
       "\n",
       "      answer_word_start answer_end answer_word_end  \\\n",
       "0                  [14]      [133]            [22]   \n",
       "1                  [90]      [609]            [95]   \n",
       "2                  [73]      [540]            [86]   \n",
       "3                  [83]      [548]            [84]   \n",
       "4                  [35]      [271]            [40]   \n",
       "...                 ...        ...             ...   \n",
       "70838               [5]       [39]             [6]   \n",
       "70839              [11]      [109]            [13]   \n",
       "70840              [20]      [170]            [22]   \n",
       "70841              [45]      [322]            [47]   \n",
       "70842              [79]      [534]            [81]   \n",
       "\n",
       "                                             answer_text  \n",
       "0      [enforce the law, protect property, and limit ...  \n",
       "1           [military units charged with civil policing]  \n",
       "2      [military or other organizations involved in t...  \n",
       "3                                        [through taxes]  \n",
       "4                   [late 18th and early 19th centuries]  \n",
       "...                                                  ...  \n",
       "70838                                      [\"non\" words]  \n",
       "70839               [new, positive-sounding terminology]  \n",
       "70840                       [civil society organization]  \n",
       "70841                      [citizen sector organization]  \n",
       "70842                      [Social Benefit Organization]  \n",
       "\n",
       "[70843 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7bcbc5",
   "metadata": {},
   "source": [
    "## Clean and transform data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21fd72d",
   "metadata": {},
   "source": [
    "#### Clean text\n",
    "What should we do? just lowering everyhting? remove stopwords? how will that work with the answer start number???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eae2f69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/andreastettejessen/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "nltk.download('wordnet')\n",
    "\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "GOOD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "try:\n",
    "    STOPWORDS = set(stopwords.words('english'))\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "    STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "\n",
    "def lower(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Transforms given text to lower case.\n",
    "    Example:\n",
    "    Input: 'I really like New York city'\n",
    "    Output: 'i really like new your city'\n",
    "    \"\"\"\n",
    "\n",
    "    return text.lower()\n",
    "\n",
    "def replace_special_characters(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Replaces special characters, such as paranthesis,\n",
    "    with spacing character\n",
    "    \"\"\"\n",
    "\n",
    "    return REPLACE_BY_SPACE_RE.sub(' ', text)\n",
    "\n",
    "def filter_out_uncommon_symbols(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Removes any special character that is not in the\n",
    "    good symbols list (check regular expression)\n",
    "    \"\"\"\n",
    "\n",
    "    return GOOD_SYMBOLS_RE.sub('', text)\n",
    "\n",
    "def remove_stopwords(text: str) -> str:\n",
    "    return ' '.join([x for x in text.split() if x and x not in STOPWORDS])\n",
    "\n",
    "def strip_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Removes any left or right spacing (including carriage return) from text.\n",
    "    Example:\n",
    "    Input: '  This assignment is cool\\n'\n",
    "    Output: 'This assignment is cool'\n",
    "    \"\"\"\n",
    "\n",
    "    return text.strip()    \n",
    "\n",
    "def lemmatize_words(text: str ) -> str:\n",
    "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "\n",
    "PREPROCESSING_PIPELINE = [\n",
    "                          lower,\n",
    "                          strip_text\n",
    "                          ]\n",
    "\n",
    "def text_prepare(text: str,\n",
    "                 filter_methods: List[Callable[[str], str]] = None) -> str:\n",
    "    \"\"\"\n",
    "    Applies a list of pre-processing functions in sequence (reduce).\n",
    "    Note that the order is important here!\n",
    "    \"\"\"\n",
    "\n",
    "    filter_methods = filter_methods if filter_methods is not None else PREPROCESSING_PIPELINE\n",
    "    if type(text) == list:\n",
    "        new_row = [reduce(lambda txt, f: f(txt), filter_methods, x) for x in text]\n",
    "    else:\n",
    "        new_row = reduce(lambda txt, f: f(txt), filter_methods, text)\n",
    "    return new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f8f8fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_be_cleaned = [\"context\", \"question\", \"answer_text\"]\n",
    "for key in to_be_cleaned:\n",
    "    train_df[key] = train_df[key].apply(lambda txt: text_prepare(txt))\n",
    "    val_df[key] = val_df[key].apply(lambda txt: text_prepare(txt))\n",
    "    test_df[key] = test_df[key].apply(lambda txt: text_prepare(txt))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd709782",
   "metadata": {},
   "source": [
    "#### Make tokenixer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7806c773",
   "metadata": {},
   "source": [
    "### THINGS TO THINK ABOUT\n",
    "- Now its the padding is exstream! The questions has to be 3706 caracters long!\n",
    "- We are only fitting on text the train context and questions. Should this also be done for val/train?\n",
    "- Preprocessing is only lowering the words. Should we do more, like removing stopwords? In that case we need to consider the answer_start index. This has to be corrected after removal of carachters\n",
    "- OOV are handeled with index 1 and will all have weights 0 in the beginning. is this correct?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbb6c3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The tokenizer will have an index 1 for OOV words. A lot of words in test and val will be 1.\n",
    "tokenizer = Tokenizer(oov_token=1)\n",
    "\n",
    "tokenizer.fit_on_texts(train_df[\"context\"])\n",
    "tokenizer.fit_on_texts(train_df[\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bc851ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find max sentence lenght for the context\n",
    "MAX_SEQ_LEN = np.max([len(row.split(' ')) for row in train_df[\"context\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d428503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "562"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SEQ_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "175d5732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def textToTensor(tokenizer, max_len, text):\n",
    "    '''\n",
    "        Converts text to tensors by converting the words into the correct indexes. \n",
    "        Then padds the tensors with 0 vlaues\n",
    "    '''\n",
    "    seq = tokenizer.texts_to_sequences(text)\n",
    "    padded = pad_sequences(sequences=seq, maxlen=max_len, padding='post')\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abf2d75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_train = textToTensor(tokenizer, MAX_SEQ_LEN, train_df[\"context\"])\n",
    "question_train = textToTensor(tokenizer, MAX_SEQ_LEN, train_df[\"question\"])\n",
    "\n",
    "context_val = textToTensor(tokenizer, MAX_SEQ_LEN, val_df[\"context\"])\n",
    "question_val = textToTensor(tokenizer, MAX_SEQ_LEN, val_df[\"question\"])\n",
    "\n",
    "context_test = textToTensor(tokenizer, MAX_SEQ_LEN, test_df[\"context\"])\n",
    "question_test = textToTensor(tokenizer, MAX_SEQ_LEN, test_df[\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "002a7459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes only the first answer: simplification\n",
    "# Can do this because we know there are only one answer for each question in our dataset\n",
    "# Might need to change this\n",
    "index_start_train = to_categorical(np.array(train_df[\"answer_word_start\"].str[0]), num_classes=MAX_SEQ_LEN)\n",
    "index_end_train = to_categorical(np.array(train_df[\"answer_word_end\"].str[0]), num_classes=MAX_SEQ_LEN)\n",
    "\n",
    "index_start_val = to_categorical(np.array(val_df[\"answer_word_start\"].str[0]), num_classes=MAX_SEQ_LEN)\n",
    "index_end_val = to_categorical(np.array(val_df[\"answer_word_end\"].str[0]), num_classes=MAX_SEQ_LEN)\n",
    "\n",
    "index_start_test = np.array(train_df[\"answer_word_start\"].str[0])\n",
    "index_end_test = np.array(train_df[\"answer_word_end\"].str[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97970acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find size of vocabulary\n",
    "VOCABULARY_SIZE = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14113eb",
   "metadata": {},
   "source": [
    "### Applying glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ade4fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim \n",
    "import gensim.downloader as gloader\n",
    "\n",
    "def load_embedding_model(embedding_dimension: int = 50) -> gensim.models.keyedvectors.KeyedVectors:\n",
    "    download_path = \"glove-wiki-gigaword-{}\".format(embedding_dimension)\n",
    "    # Check download\n",
    "    try:\n",
    "        emb_model = gloader.load(download_path)\n",
    "    except ValueError as e:\n",
    "        print(\"Invalid embedding model name! Check the embedding dimension:\")\n",
    "        print(\"Word2Vec: 300\")\n",
    "        print(\"Glove: 50, 100, 200, 300\")\n",
    "        raise e\n",
    "\n",
    "    return emb_model\n",
    "    \n",
    "def create_embedding_matrix(embedding_model, embedding_dimension, word_to_idx):\n",
    "    embedding_matrix = np.zeros((len(word_to_idx)+1, embedding_dimension), dtype=np.float32)\n",
    "    for word, idx in word_to_idx.items():\n",
    "        try:\n",
    "            embedding_vector = embedding_model[word]\n",
    "        except (KeyError, TypeError):\n",
    "            embedding_vector = np.random.uniform(low=-0.05, high=0.05, size=embedding_dimension)\n",
    "\n",
    "        embedding_matrix[idx] = embedding_vector\n",
    "                                \n",
    "    return embedding_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c6a3717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81463, 50)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dimension = 50\n",
    "\n",
    "embedding_model = load_embedding_model(embedding_dimension)\n",
    "embedding_matrix = create_embedding_matrix(embedding_model, embedding_dimension, tokenizer.word_index)\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d1d9ba",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52146b3f",
   "metadata": {},
   "source": [
    "##### Similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4a3266a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Similarity(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Similarity, self).__init__(**kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        shape = input_shape[0][-1]*3\n",
    "        self.kernel = self.add_weight(name='similarity_weight',\n",
    "                                        shape=(shape, 1),\n",
    "                                        initializer='uniform',\n",
    "                                        trainable=True)\n",
    "        super(Similarity, self).build(input_shape)\n",
    "    def get_kernel(self):\n",
    "        return self.kernel\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        A, B = inputs\n",
    "        A_dim_repeat = K.concatenate([[1, 1], [A.shape[1]], [1]], 0)\n",
    "        B_dim_repeat = K.concatenate([[1], [B.shape[1]], [1, 1]], 0)\n",
    "        A_repeated = K.tile(K.expand_dims(A, axis=2), A_dim_repeat)\n",
    "        B_repeated = K.tile(K.expand_dims(B, axis=1), B_dim_repeat)\n",
    "        element_wise_multiplication = A_repeated * B_repeated\n",
    "        concated = K.concatenate([A_repeated, B_repeated, element_wise_multiplication], axis=-1)\n",
    "        dot= K.dot(concated, self.kernel)\n",
    "        dot_product = K.squeeze(dot, axis=-1)\n",
    "        return dot_product\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        batch_size = input_shape[0][0]\n",
    "        num_context_words = input_shape[0][1]\n",
    "        num_query_words = input_shape[1][1]\n",
    "        return (batch_size, num_context_words, num_query_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b91594",
   "metadata": {},
   "source": [
    "##### C2q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db4b9e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Context2QuestionAttention(Layer):\n",
    "    '''\n",
    "    A = Take row-wise softmax of the similarity matrix\n",
    "    Û = For every row in A (softmaxed similarity matrix), A_t:\n",
    "        Multiply every element in A_t calculate the weighted sum of the question matrix. \n",
    "        (The weigths will be the elements in A_t)\n",
    "    Input: Question matrix and similarity matrix\n",
    "    '''\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Context2QuestionAttention, self).__init__(**kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        super(Context2QuestionAttention, self).build(input_shape)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        question_encoding, similarity_matrix, mask = inputs\n",
    "\n",
    "        masked_inp = tf.where(mask>0, similarity_matrix, tf.float64.min)\n",
    "        # Take only soft max on non padded values\n",
    "        softmax_similarity_matrix1 = Softmax(axis=-1)(masked_inp)\n",
    "        softmax_similarity_matrix = tf.where(tf.math.is_nan(softmax_similarity_matrix1)!=True, softmax_similarity_matrix1, 0)\n",
    "\n",
    "        question_encoding_expand = K.expand_dims(question_encoding, axis=1)\n",
    "        softmax_similarity_matrix_expand = K.expand_dims(softmax_similarity_matrix, axis=-1)\n",
    "        product = softmax_similarity_matrix_expand*question_encoding_expand\n",
    "        summ = K.sum(product, axis=-2)\n",
    "        \n",
    "        return summ\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        question_encoding_shape, _ = input_shape\n",
    "        batch_size = question_encoding_shape[0]\n",
    "        max_seq_len = question_encoding_shape[1]\n",
    "        embedding_dim = question_encoding_shape[2]\n",
    "        return (batch_size,max_seq_len, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc5871f",
   "metadata": {},
   "source": [
    "##### q2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5acee72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Question2ContextAttention(Layer):\n",
    "    '''\n",
    "    Similraity matrix [max_seq_len, max_seq_len]\n",
    "    Z = maximum across each row of the similarity matrix [max_seq_len, 1]\n",
    "    b = softmax on Z to get attention distribution (max_seq_len, 1)\n",
    "    ^h = Use b to take a weigthed sum of the contex matrix H (max_seq_len, 1)\n",
    "    ^H = ^h dubplicated max_seq_len times (max_seq_len, max_seq_len)\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super(Question2ContextAttention, self).__init__(**kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        super(Question2ContextAttention, self).build(input_shape)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        context_encoding, similarity_matrix, mask = inputs\n",
    "\n",
    "        masked_inp = tf.where(mask>0, similarity_matrix, 0)\n",
    "        max_sim_matrix = K.max(masked_inp, axis=-1) # K.max also squeezes\n",
    "        # Take only softmax on non padded vlaues\n",
    "        masked_inp2 = tf.where(max_sim_matrix!=0, max_sim_matrix, tf.float64.min)\n",
    "        softmax_similarity_matrix = Softmax(axis=-1)(masked_inp2)\n",
    "        softmax_similarity_matrix = tf.where(tf.math.is_nan(softmax_similarity_matrix)!=True, softmax_similarity_matrix, 0)\n",
    "\n",
    "        softmax_similarity_matrix_expand = K.expand_dims(softmax_similarity_matrix, axis=-1)\n",
    "        product = softmax_similarity_matrix_expand*context_encoding\n",
    "        weighted_sum = K.sum(product, axis=-2)\n",
    "        # Expand dimensions, so that vector can be repeated\n",
    "        expanded_weighted_sum = K.expand_dims(weighted_sum, 1)\n",
    "        # get max_seq_len\n",
    "        max_seq_len = K.shape(context_encoding)[1]\n",
    "        # repeat vector for max seq length to make matrix\n",
    "        question2context_attention = K.tile(expanded_weighted_sum, [1, max_seq_len, 1])\n",
    "        return question2context_attention\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        batch_size = input_shape[0][0]\n",
    "        num_context_words = input_shape[0][1]\n",
    "        num_query_words = input_shape[1][1]\n",
    "        return (batch_size, num_context_words, num_query_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005817f6",
   "metadata": {},
   "source": [
    "##### Mega merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "26586890",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MegaMerge(Layer):\n",
    "    '''\n",
    "    For each word in max_seqence_length (T):\n",
    "        cu = context elementwise multiply with Û (c2q) (2d, T)\n",
    "        ch = context elementwise multiply with ^H (q2c) (2d, T)\n",
    "        Stack for each column context, Û, cu, ch. [8*embedding_dim, 1]\n",
    "    Output:\n",
    "    mega_merge (8d, T)\n",
    "\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super(MegaMerge, self).__init__(**kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        super(MegaMerge, self).build(input_shape)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        context_encoding, context2question_attention, question2context_attention = inputs\n",
    "\n",
    "        element_wise_multiply1 = context_encoding * context2question_attention\n",
    "        element_wise_multiply2 = context_encoding * question2context_attention\n",
    "\n",
    "        mega_merge = K.concatenate([context_encoding, context2question_attention, element_wise_multiply1, element_wise_multiply2], axis=-1)\n",
    "        return mega_merge\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        context_encoding_shape , _, _ = input_shape\n",
    "        batch_size = context_encoding_shape[0]\n",
    "        max_seq_len = context_encoding_shape[1]\n",
    "        embedding_dim2 = context_encoding_shape[2]\n",
    "        return (batch_size, max_seq_len, embedding_dim2*4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe85d948",
   "metadata": {},
   "source": [
    "##### Output layer start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "024311f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StartOutput(Layer):\n",
    "    '''\n",
    "    1. super merge = Concatenate first hidden_layer(T,2d) with Mega merge(T,8d)\n",
    "    Make trainable weigths (10d, 1)\n",
    "    2. dotted = Dotproduct with trainable weigths and super merge (T,1)\n",
    "    3. out = Softmax the dotted vector (T,1)\n",
    "    Output:\n",
    "    out (T,1)\n",
    "\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super(StartOutput, self).__init__(**kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        shape = input_shape[0][-1]*5 # want 10*embedding dimention\n",
    "        self.kernel = self.add_weight(name='startOutput_weight',\n",
    "                                        shape=(shape, 1),\n",
    "                                        initializer='uniform',\n",
    "                                        trainable=True)\n",
    "        super(StartOutput, self).build(input_shape)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        hidden_layer, mega_merge, mask = inputs\n",
    "\n",
    "        super_merge = K.concatenate([mega_merge, hidden_layer])\n",
    "        dotted = K.squeeze(K.dot(super_merge, self.kernel), axis=-1)\n",
    "        masked_inp = tf.where(mask!=False, dotted, tf.float64.min)\n",
    "        # OBS try without mask stuff. With mask change dotted to be masked_inp\n",
    "        soft_max_dotted = Softmax(axis=-1)(masked_inp)\n",
    "        return soft_max_dotted\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        hidden_layer , _, _ = input_shape\n",
    "        batch_size = hidden_layer[0]\n",
    "        max_seq_len = hidden_layer[1]\n",
    "        return (batch_size, max_seq_len, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a4585190",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EndOutput(Layer):\n",
    "    '''\n",
    "    1. super merge = Concatenate second hidden layer with Mega merge\n",
    "    Make trainable weigths (10d, 1)\n",
    "    2. dotted = Dotproduct with trainable weigths and super merge (T,1)\n",
    "    3. out = Softmax the dotted vector (T,1)\n",
    "    Output:\n",
    "    out (T,1)\n",
    "\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super(EndOutput, self).__init__(**kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        shape = input_shape[0][-1]*5 # want 10*embedding dimention\n",
    "        self.kernel = self.add_weight(name='endOutput_weight',\n",
    "                                        shape=(shape, 1),\n",
    "                                        initializer='uniform',\n",
    "                                        trainable=True)\n",
    "        super(EndOutput, self).build(input_shape)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        hidden_layer, mega_merge, mask = inputs\n",
    "        super_merge = K.concatenate([mega_merge, hidden_layer])\n",
    "\n",
    "        dotted = K.squeeze(K.dot(super_merge, self.kernel), axis=-1)\n",
    "        masked_inp = tf.where(mask!=False, dotted, tf.float64.min)\n",
    "        # OBS try without mask stuff. With mask change dotted to be masked_inp\n",
    "        soft_max_dotted = Softmax(axis=-1)(masked_inp)\n",
    "        return soft_max_dotted\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        hidden_layer , _, _ = input_shape\n",
    "        batch_size = hidden_layer[0]\n",
    "        max_seq_len = hidden_layer[1]\n",
    "        return (batch_size, max_seq_len, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d13737a",
   "metadata": {},
   "source": [
    "##### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69cb3a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(max_tokens, vocab_size, embedding_dimension):\n",
    "    '''\n",
    "        Creates keras model for classification.\n",
    "        Inputs: \n",
    "            max_tokens (int): Max length of a text sequence\n",
    "            vocab_size (int): Size of the vocabulary\n",
    "            embedding_dimension (int): The dimension of the embedding vectors\n",
    "    '''   \n",
    "\n",
    "    #-------------------------- Input layer ------------------------------------------------------------\n",
    "    question_input = Input(shape=(max_tokens, ))\n",
    "    context_input = Input(shape=(max_tokens, ))\n",
    "    #-----------------------------------------------------------------------------------------------------\n",
    "\n",
    "    #-------------------------- Word embedding ------------------------------------------------------------\n",
    "    question_embedding = Embedding(vocab_size, embedding_dimension, weights = [embedding_matrix], name='WordEmbedding_question', trainable = False, mask_zero = True)(question_input)\n",
    "    context_embedding = Embedding(vocab_size, embedding_dimension, weights = [embedding_matrix], name='WordEmbedding_context', trainable = False, mask_zero = True)(context_input)\n",
    "    #-----------------------------------------------------------------------------------------------------\n",
    "\n",
    "    #-------------------------- Encoding/sentence embedding -------------------------------------------------------\n",
    "    # Encode token sequences with bi-directional LSTM and concatenate the series of hidden vectors (done by default)\n",
    "    question_encoding = Bidirectional(LSTM(embedding_dimension, return_sequences=True, name='SentenceEmbedding_claims'))(question_embedding)\n",
    "    context_encoding = Bidirectional(LSTM(embedding_dimension, return_sequences=True, name='SentenceEmbedding_evidence'))(context_embedding)\n",
    "    #-----------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # OBS addef the mask to remove padding\n",
    "    emb = Embedding(vocab_size, embedding_dimension, weights = [embedding_matrix], name='WordEmbedding_context', trainable = False, mask_zero = True)\n",
    "    \n",
    "    mask_question = emb.compute_mask(question_input)\n",
    "    mask_context = emb.compute_mask(context_input)\n",
    "\n",
    "    mask_question_int = tf.cast(mask_question, tf.float32)\n",
    "    mask_context_int = tf.cast(mask_context, tf.float32)\n",
    "\n",
    "    mask_question_expand = tf.expand_dims(mask_question_int, 1)\n",
    "    mask_context_expand = tf.expand_dims(mask_context_int, 2)\n",
    "\n",
    "    combined_mask = mask_context_expand * mask_question_expand\n",
    "\n",
    "    #-------------------------- Similarity ------------------------------------------------------------\n",
    "    similarity_layer = Similarity()\n",
    "    similarity_matrix = similarity_layer([question_encoding, context_encoding])\n",
    "\n",
    "    # Replacing values in similarity matrix where context is padding \n",
    "    masked_similarity_matrix = tf.where(combined_mask>0, similarity_matrix, 0)\n",
    "    #-------------------------- Attention ------------------------------------------------------------\n",
    "    c2q = Context2QuestionAttention()\n",
    "    context2question_attention = c2q([question_encoding, masked_similarity_matrix, combined_mask])\n",
    "\n",
    "    q2c = Question2ContextAttention()\n",
    "    question2context_attention = q2c([context_encoding, masked_similarity_matrix, combined_mask])\n",
    "    #-----------------------------------------------------------------------------------------------------\n",
    "\n",
    "    #-------------------------- Megamerge --------------------------------------------------------------\n",
    "    mm = MegaMerge()\n",
    "    mega_merge = mm([context_encoding, context2question_attention, question2context_attention])\n",
    "\n",
    "    #-------------------------- Model layer --------------------------------------------------------------\n",
    "    hidden_layer = Bidirectional(LSTM(embedding_dimension, return_sequences=True))(mega_merge)\n",
    "    hidden_layer2 = Bidirectional(LSTM(embedding_dimension, return_sequences=True))(hidden_layer)\n",
    "    #-----------------------------------------------------------------------------------------------------\n",
    "\n",
    "    #-------------------------- Output layer -------------------------------------------------------------\n",
    "    start_out_model = StartOutput(name=\"start_output\")\n",
    "    start_probabilities = start_out_model([hidden_layer, mega_merge, mask_context])\n",
    "\n",
    "    end_out_model = EndOutput(name=\"end_output\")\n",
    "    end_probabilities = end_out_model([hidden_layer2, mega_merge, mask_context])\n",
    "\n",
    "    return Model(inputs=[question_input, context_input], outputs=[start_probabilities, end_probabilities])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c1467a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 562)]        0           []                               \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, 562)]        0           []                               \n",
      "                                                                                                  \n",
      " tf.math.not_equal_1 (TFOpLambd  (None, 562)         0           ['input_2[0][0]']                \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.not_equal (TFOpLambda)  (None, 562)         0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " tf.cast_1 (TFOpLambda)         (None, 562)          0           ['tf.math.not_equal_1[0][0]']    \n",
      "                                                                                                  \n",
      " tf.cast (TFOpLambda)           (None, 562)          0           ['tf.math.not_equal[0][0]']      \n",
      "                                                                                                  \n",
      " WordEmbedding_context (Embeddi  (None, 562, 50)     4073150     ['input_2[0][0]']                \n",
      " ng)                                                                                              \n",
      "                                                                                                  \n",
      " WordEmbedding_question (Embedd  (None, 562, 50)     4073150     ['input_1[0][0]']                \n",
      " ing)                                                                                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_1 (TFOpLambda)  (None, 562, 1)       0           ['tf.cast_1[0][0]']              \n",
      "                                                                                                  \n",
      " tf.expand_dims (TFOpLambda)    (None, 1, 562)       0           ['tf.cast[0][0]']                \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  (None, 562, 100)    40400       ['WordEmbedding_context[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 562, 100)     40400       ['WordEmbedding_question[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None, 562, 562)     0           ['tf.expand_dims_1[0][0]',       \n",
      "                                                                  'tf.expand_dims[0][0]']         \n",
      "                                                                                                  \n",
      " tf.math.greater (TFOpLambda)   (None, 562, 562)     0           ['tf.math.multiply[0][0]']       \n",
      "                                                                                                  \n",
      " similarity (Similarity)        (None, 562, 562)     300         ['bidirectional[0][0]',          \n",
      "                                                                  'bidirectional_1[0][0]']        \n",
      "                                                                                                  \n",
      " tf.where (TFOpLambda)          (None, 562, 562)     0           ['tf.math.greater[0][0]',        \n",
      "                                                                  'similarity[0][0]']             \n",
      "                                                                                                  \n",
      " context2_question_attention (C  (None, 562, 100)    0           ['bidirectional[0][0]',          \n",
      " ontext2QuestionAttention)                                        'tf.where[0][0]',               \n",
      "                                                                  'tf.math.multiply[0][0]']       \n",
      "                                                                                                  \n",
      " question2_context_attention (Q  (None, 562, 100)    0           ['bidirectional_1[0][0]',        \n",
      " uestion2ContextAttention)                                        'tf.where[0][0]',               \n",
      "                                                                  'tf.math.multiply[0][0]']       \n",
      "                                                                                                  \n",
      " mega_merge (MegaMerge)         (None, 562, 400)     0           ['bidirectional_1[0][0]',        \n",
      "                                                                  'context2_question_attention[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'question2_context_attention[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " bidirectional_2 (Bidirectional  (None, 562, 100)    180400      ['mega_merge[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bidirectional_3 (Bidirectional  (None, 562, 100)    60400       ['bidirectional_2[0][0]']        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " start_output (StartOutput)     (None, 562)          500         ['bidirectional_2[0][0]',        \n",
      "                                                                  'mega_merge[0][0]',             \n",
      "                                                                  'tf.math.not_equal_1[0][0]']    \n",
      "                                                                                                  \n",
      " end_output (EndOutput)         (None, 562)          500         ['bidirectional_3[0][0]',        \n",
      "                                                                  'mega_merge[0][0]',             \n",
      "                                                                  'tf.math.not_equal_1[0][0]']    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8,469,200\n",
      "Trainable params: 322,900\n",
      "Non-trainable params: 8,146,300\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(MAX_SEQ_LEN, VOCABULARY_SIZE, 50)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636d7b10",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf765654",
   "metadata": {},
   "outputs": [],
   "source": [
    "_EPSILON = 1e-7\n",
    "def categorical_cross_entropy_loss(target, output):\n",
    "    output /= tf.reduce_sum(output, -1, True)\n",
    "    # manual computation of crossentropy\n",
    "    epsilon = K.constant(_EPSILON, output.dtype.base_dtype)\n",
    "    output = tf.clip_by_value(output, epsilon, 1. - epsilon)\n",
    "    return - tf.reduce_sum(target * tf.math.log(output), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "862b4b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {\"start_output\": categorical_cross_entropy_loss, \"end_output\": categorical_cross_entropy_loss}\n",
    "\n",
    "lossWeights = {\"start_output\": 1.0, \"end_output\": 1.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d764db15",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = tf.keras.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2439b43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      " 101/8856 [..............................] - ETA: 68:40:14 - loss: 9.2665 - start_output_loss: 4.6652 - end_output_loss: 4.6013 - start_output_categorical_accuracy: 0.0371 - end_output_categorical_accuracy: 0.0384"
     ]
    }
   ],
   "source": [
    "model.compile(loss=losses,\n",
    "              loss_weights=lossWeights, \n",
    "              optimizer=adam,\n",
    "              metrics=['categorical_accuracy'])\n",
    "history = model.fit(x=[question_train, context_train], y= {\"start_output\": index_start_train, \"end_output\": index_end_train}, batch_size=8, epochs=2, validation_data=([question_val, context_val], {\"start_output\": index_start_val, \"end_output\": index_end_val}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07a69f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c869b93",
   "metadata": {},
   "source": [
    "### Funcitons for saving the models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260bdc41",
   "metadata": {},
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b23d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tokenizer(dir, model_name, tokenizer):\n",
    "    path = f'{dir}/{model_name}/tokenizer.txt'\n",
    "    print(f'Saving tokenizer to {path}')\n",
    "    with open(path, 'w') as file:\n",
    "     file.write(json.dumps(tokenizer.word_index))\n",
    "\n",
    "def save_max_seq_len(dir, model_name, MAX_SEQ_LEN):\n",
    "    path = f'{dir}/{model_name}/MAX_SEQ_LEN.txt'\n",
    "    print(f'Saving max seq len to {path}')\n",
    "    with open(path, 'w') as file:\n",
    "     file.write(json.dumps(MAX_SEQ_LEN))\n",
    "\n",
    "def save_model(model, tokenizer, MAX_SEQ_LEN, dir='models'):\n",
    "    '''\n",
    "        Saves model naming it according to sentence embedding merge type and time stamp.\n",
    "    '''\n",
    "    now = datetime.now()\n",
    "    dt_string = now.strftime(\"%d_%m_%Y_%H:%M:%S\")\n",
    "    model_name = f'model_{dt_string}'\n",
    "    path = f'{dir}/{model_name}/model/'\n",
    "    model.save(path)\n",
    "    save_tokenizer(dir, model_name, tokenizer)\n",
    "    save_max_seq_len(dir, model_name, MAX_SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d116c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, tokenizer, MAX_SEQ_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d25a8f4",
   "metadata": {},
   "source": [
    "#### Plot accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac54c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(model_callback):\n",
    "    plt.plot(model_callback.history['acc'])\n",
    "    plt.plot(model_callback.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "def plot_loss(model_callback):\n",
    "    plt.plot(model_callback.history['loss'])\n",
    "    plt.plot(model_callback.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "def plot_confusion_matrix(confusion_matrix):\n",
    "\n",
    "    ax = sns.heatmap(confusion_matrix, annot=True, cmap='Blues', fmt='d')\n",
    "\n",
    "    ax.set_title('Confusion Matrix\\n\\n')\n",
    "    ax.set_xlabel('\\nPredicted Values')\n",
    "    ax.set_ylabel('Actual Values ')\n",
    "\n",
    "    ## Ticket labels - List must be in alphabetical order\n",
    "    ax.xaxis.set_ticklabels(['False','True'])\n",
    "    ax.yaxis.set_ticklabels(['False','True'])\n",
    "\n",
    "    ## Display the visualization of the Confusion Matrix.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f990c16d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/t4/vnxj6kkj2n97knry5lnrscx00000gn/T/ipykernel_52353/2189927672.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplot_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/t4/vnxj6kkj2n97knry5lnrscx00000gn/T/ipykernel_52353/3317561991.py\u001b[0m in \u001b[0;36mplot_accuracy\u001b[0;34m(model_callback)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_callback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'acc'"
     ]
    }
   ],
   "source": [
    "plot_loss(history)\n",
    "plot_accuracy(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
