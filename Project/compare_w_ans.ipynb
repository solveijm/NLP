{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(dataset_path=\"SQUAD MATERIAL/test_set.json\"):\n",
    "        '''Load testdata from json file'''    \n",
    "        with open(dataset_path) as f:\n",
    "            raw_json = json.load(f)\n",
    "\n",
    "        return raw_json['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsn = load_json(\"SQUAD MATERIAL/training_set.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"SQUAD MATERIAL/test_set.json\", 'w') as f:\n",
    "    d = {'data': jsn[0:4]}\n",
    "    raw_json = json.dump(d, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_word_index(char_idx, context):\n",
    "    return context[0:char_idx].count(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(data):\n",
    "    contexts = []\n",
    "    questions = []\n",
    "    answers_text = []\n",
    "    answers_start = []\n",
    "    answers_end = []\n",
    "    question_ids = []\n",
    "    answers_word_start = []\n",
    "    answers_word_end = []\n",
    "    for i in range(len(data)):\n",
    "        paragraphs = data[i]['paragraphs']\n",
    "        for sub_para in paragraphs:\n",
    "            for q_a in sub_para['qas']:\n",
    "                questions.append(q_a['question'])\n",
    "                q_a_answer_starts = []\n",
    "                q_a_answer_ends = []\n",
    "                q_a_answers = []\n",
    "                q_a_ans_word_idx_start = []\n",
    "                q_a_ans_word_idx_end = []\n",
    "\n",
    "                for answer in q_a['answers']:\n",
    "                    answer_end = answer['answer_start'] + len(answer['text'])\n",
    "                    q_a_answer_starts.append(answer['answer_start'])\n",
    "                    q_a_answer_ends.append(answer_end)\n",
    "                    q_a_answers.append(answer['text'])\n",
    "                    q_a_ans_word_idx_start.append(find_word_index(answer['answer_start'], sub_para['context']))\n",
    "                    q_a_ans_word_idx_end.append(find_word_index(answer_end, sub_para['context']))\n",
    "                    \n",
    "                answers_start.append(q_a_answer_starts)\n",
    "                answers_end.append(q_a_answer_ends)\n",
    "                answers_word_start.append(q_a_ans_word_idx_start)                \n",
    "                answers_word_end.append(q_a_ans_word_idx_end)\n",
    "                answers_text.append(q_a_answers)\n",
    "                question_ids.append(q_a['id'])\n",
    "                contexts.append(sub_para['context'])   \n",
    "    df = pd.DataFrame({\"questionID\":question_ids, \"answer_text\": answers_text, \"context\":contexts, \"question\": questions, \"answer_start\": answers_start, \"answer_word_start\": answers_word_start, \"answer_end\": answers_end, \"answer_word_end\": answers_word_end})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_json()\n",
    "df = create_dataframe(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40    5733ae924776f41900661013\n",
       "41    5733ae924776f41900661015\n",
       "42    5733ae924776f41900661016\n",
       "43    5733ae924776f41900661017\n",
       "44    5733afd3d058e614000b6045\n",
       "45    5733afd3d058e614000b6047\n",
       "46    5733afd3d058e614000b6048\n",
       "47    5733afd3d058e614000b6046\n",
       "48    5733afd3d058e614000b6049\n",
       "49    5733b0fb4776f41900661041\n",
       "50    5733b0fb4776f41900661043\n",
       "51    5733b0fb4776f41900661044\n",
       "52    5733b0fb4776f41900661045\n",
       "53    5733b0fb4776f41900661042\n",
       "54    5733b1da4776f41900661068\n",
       "55    5733b1da4776f41900661069\n",
       "56    5733b1da4776f4190066106a\n",
       "57    5733b1da4776f4190066106b\n",
       "58    5733b1da4776f41900661067\n",
       "59    5733b2fe4776f4190066108f\n",
       "Name: questionID, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['questionID'][40:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40                                 [19.7%]\n",
       "41        [the top 10 to 15 in the nation]\n",
       "42                                 [39.1%]\n",
       "43                   [more than 750 miles]\n",
       "44                          [18th overall]\n",
       "45                                   [8th]\n",
       "46                           [1st overall]\n",
       "47                             [USA Today]\n",
       "48                                 [57.6%]\n",
       "49         [Father Joseph Carrier, C.S.C.]\n",
       "50                             [1851–1921]\n",
       "51                [the Science Department]\n",
       "52                   [Evolution and Dogma]\n",
       "53    [Professor of Chemistry and Physics]\n",
       "54                                  [1882]\n",
       "55                [Professor Jerome Green]\n",
       "56                           [Around 1899]\n",
       "57               [Father Julius Nieuwland]\n",
       "58                  [an early wind tunnel]\n",
       "59                  [The Lobund Institute]\n",
       "Name: answer_text, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['answer_text'][40:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "# File for using the trained models to get predictions\n",
    "#------------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import json\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import sys\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "\n",
    "_EPSILON = 1e-7\n",
    "def categorical_cross_entropy_loss(target, output):\n",
    "    output /= tf.reduce_sum(output, -1, True)\n",
    "    # manual computation of crossentropy\n",
    "    epsilon = K.constant(_EPSILON, output.dtype.base_dtype)\n",
    "    output = tf.clip_by_value(output, epsilon, 1. - epsilon)\n",
    "    return - tf.reduce_sum(target * tf.math.log(output), -1)\n",
    "\n",
    "losses = {\"start_output\": categorical_cross_entropy_loss, \"end_output\": categorical_cross_entropy_loss}\n",
    "\n",
    "lossWeights = {\"start_output\": 1.0, \"end_output\": 1.0}\n",
    "# Load model\n",
    "def load_model(dir='./models/model_22_12_2021_11_16_34'):\n",
    "    '''\n",
    "        - Load the trained model using keras.models.load_model\n",
    "        - Load the tokenizer word index to give the words \n",
    "        the same index as in training.\n",
    "        - Load MAX_SEQ_LEN used in training to pad testset \n",
    "        to the correct length.\n",
    "        Outputs:\n",
    "            Trained model\n",
    "            Tokenizer word to index dictionary\n",
    "            Max sequence length (int)\n",
    "    '''\n",
    "    print(\"Loading model...\")\n",
    "    model = keras.models.load_model(f'{dir}/model', custom_objects={'test_loss':categorical_cross_entropy_loss})\n",
    "    with open(f'{dir}/tokenizer.txt') as f:\n",
    "        tokenizer_word_index = json.load(f)\n",
    "    with open(f'{dir}/MAX_SEQ_LEN.txt') as f:\n",
    "        MAX_SEQ_LEN = json.load(f)\n",
    "    return model, tokenizer_word_index, MAX_SEQ_LEN\n",
    "\n",
    "\n",
    "def get_test_data(path, tokenizer_word_index, MAX_SEQ_LEN):\n",
    "    '''\n",
    "        Loads testdata, makes it into a dataframe, lower the \n",
    "        text and strip text and tokenize the words using the \n",
    "        word_index dict from training and padds sequences.\n",
    "        Input:\n",
    "            Path to the testdata file\n",
    "            tokenizer word index list from training\n",
    "            MAX_SEQ_LEN (int) used in training\n",
    "        Ouput:\n",
    "            tokenized context (np.array)\n",
    "            tokenized question (np.array)\n",
    "            dataframe\n",
    "\n",
    "    '''\n",
    "    print(f'Get test data from {path}')\n",
    "    # Import json file from path\n",
    "    def load_json(dataset_path=\"training_set.json\"):\n",
    "        '''Load testdata from json file'''    \n",
    "        with open(dataset_path) as f:\n",
    "            raw_json = json.load(f)\n",
    "\n",
    "        return raw_json['data']\n",
    "\n",
    "    def create_dataframe(data):\n",
    "        '''Create dataframe of the given data'''\n",
    "        contexts = []\n",
    "        questions = []\n",
    "        question_ids = []\n",
    "        for i in range(len(data)):\n",
    "            paragraphs = data[i]['paragraphs']\n",
    "            for sub_para in paragraphs:\n",
    "                for q_a in sub_para['qas']:\n",
    "                    questions.append(q_a['question'])\n",
    "                    question_ids.append(q_a['id'])\n",
    "                    contexts.append(sub_para['context'])   \n",
    "        df = pd.DataFrame({\"questionID\":question_ids, \"context\":contexts, \"question\": questions})\n",
    "        return df\n",
    "\n",
    "    def clean_text(dataframe):\n",
    "        '''Make the text into lower and remove all leading and trailing whitespace'''\n",
    "        def lower(text: str) -> str:\n",
    "            return text.lower()\n",
    "        def strip_text(text: str) -> str:\n",
    "            return text.strip()  \n",
    "\n",
    "        PREPROCESSING_PIPELINE = [\n",
    "                            lower,\n",
    "                            strip_text\n",
    "                            ]\n",
    "\n",
    "        def text_prepare(text: str) -> str:\n",
    "            \"\"\"\n",
    "            Applies a list of pre-processing functions in sequence (reduce).\n",
    "            \"\"\"\n",
    "\n",
    "            filter_methods = PREPROCESSING_PIPELINE\n",
    "            if type(text) == list:\n",
    "                new_row = [reduce(lambda txt, f: f(txt), filter_methods, x) for x in text]\n",
    "            else:\n",
    "                new_row = reduce(lambda txt, f: f(txt), filter_methods, text)\n",
    "            return new_row\n",
    "        for key in ['context', 'question']:\n",
    "            dataframe[key] = dataframe[key].apply(lambda txt: text_prepare(txt))\n",
    "        \n",
    "        return dataframe\n",
    "\n",
    "    def textToTensor(tokenizer, max_len, text):\n",
    "        '''\n",
    "            Converts text to tensors by converting the words into the correct indexes. \n",
    "            Then padds the tensors with 0 vlaues\n",
    "        '''\n",
    "        seq = tokenizer.texts_to_sequences(text)\n",
    "        padded = pad_sequences(sequences=seq, maxlen=max_len, padding='post')\n",
    "        return padded\n",
    "\n",
    "    def tokenize(df, tokenizer_word_index, MAX_SEQ_LEN):\n",
    "        '''Creates a tokenizer using the word_index dicitonary from training'''\n",
    "        tokenizer = Tokenizer()\n",
    "        tokenizer.word_index = tokenizer_word_index\n",
    "        context = textToTensor(tokenizer, MAX_SEQ_LEN, df['context'])\n",
    "        question = textToTensor(tokenizer, MAX_SEQ_LEN, df['question'])\n",
    "        return context, question\n",
    "\n",
    "    data = load_json(path)\n",
    "    df = create_dataframe(data)\n",
    "    df = clean_text(df)\n",
    "    context, question = tokenize(df, tokenizer_word_index, MAX_SEQ_LEN)\n",
    "    return context, question, df\n",
    "\n",
    "\n",
    "def get_predicitons(model, context, questions):\n",
    "    '''Use the model to predict on the testset'''\n",
    "    print('Get predicitons..')\n",
    "    predictions = model.predict([questions, context])\n",
    "    print(\"Gotten the predcitions!\")\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def make_answer_dict(start_preds, end_preds, df):\n",
    "    '''Convert predicitons to a dicitonary containing question ID and answer text'''\n",
    "    print('Convert predicitons to answer text..')\n",
    "    def get_word_index(prediction):\n",
    "        return [np.argmax(prediction[i]) for i in range(len(prediction))]\n",
    "\n",
    "    def get_answer_text(start, end, index, df):\n",
    "        '''Get answer text from context'''\n",
    "        words = df['context'][index].split(' ')[start:end+1]\n",
    "        answ = \" \".join(words)\n",
    "        # NB!!!: fore some reason the end is projected to be before the start so the answers are empty strings. \n",
    "        # Just doing this for now.\n",
    "        if answ == \"\":\n",
    "            print(\"\\n\\nSOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\\n\\n\")\n",
    "            answ = df['context'][index].split(' ')\n",
    "            print('satrta', start)\n",
    "            print('len', len(answ))\n",
    "            answ = answ[start]\n",
    "        return answ\n",
    "\n",
    "    answer_dict = {}\n",
    "    start_indxs = get_word_index(start_preds)\n",
    "    end_indxs = get_word_index(end_preds)\n",
    "    for i in range(len(start_preds)):\n",
    "        question_id = df['questionID'][i]\n",
    "        start_index = start_indxs[i]\n",
    "        end_index = end_indxs[i]\n",
    "        answr_text = get_answer_text(start_index, end_index, i, df)\n",
    "        answer_dict[question_id] = answr_text\n",
    "    return answer_dict\n",
    "\n",
    "def write_predictions(answer_dict, path):\n",
    "    '''Write answers to a prediciton file'''\n",
    "    print(f'Saving answer to {path}')\n",
    "    with open(path, 'w') as file:\n",
    "     file.write(json.dumps(answer_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = './SQUAD MATERIAL/test_set.json'\n",
    "prediction_path = 'predictions.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-22 15:02:37.512242: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/t4/vnxj6kkj2n97knry5lnrscx00000gn/T/ipykernel_57730/2399136056.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer_word_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_SEQ_LEN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/t4/vnxj6kkj2n97knry5lnrscx00000gn/T/ipykernel_57730/2744885798.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(dir)\u001b[0m\n\u001b[1;32m     40\u001b[0m     '''\n\u001b[1;32m     41\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading model...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{dir}/model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'test_loss'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcategorical_cross_entropy_loss\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{dir}/tokenizer.txt'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mtokenizer_word_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0;34m'Filepath looks like a hdf5 file but h5py is not available.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                 f' filepath={filepath}')\n\u001b[0;32m--> 214\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m   raise IOError(\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/keras/saving/saved_model/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, compile, options)\u001b[0m\n\u001b[1;32m    140\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mnode_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaded_node\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeras_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaded_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0mnodes_to_load\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeras_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m   loaded = tf.__internal__.saved_model.load_partial(\n\u001b[0m\u001b[1;32m    143\u001b[0m       path, nodes_to_load, options=options)\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload_partial\u001b[0;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[1;32m    804\u001b[0m     \u001b[0mA\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0mnode\u001b[0m \u001b[0mpaths\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfilter\u001b[0m \u001b[0mto\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0mobjects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m   \"\"\"\n\u001b[0;32m--> 806\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mload_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload_internal\u001b[0;34m(export_dir, tags, options, loader_cls, filters)\u001b[0m\n\u001b[1;32m    936\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m         loader = loader_cls(object_graph_proto, saved_model_proto, export_dir,\n\u001b[0m\u001b[1;32m    939\u001b[0m                             ckpt_options, options, filters)\n\u001b[1;32m    940\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, object_graph_proto, saved_model_proto, export_dir, ckpt_options, save_options, filters)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_export_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexport_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     self._concrete_functions = (\n\u001b[0;32m--> 138\u001b[0;31m         function_deserialization.load_function_def_library(\n\u001b[0m\u001b[1;32m    139\u001b[0m             meta_graph.graph_def.library, wrapper_function=_WrapperFunction))\n\u001b[1;32m    140\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkpoint_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mckpt_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/saved_model/function_deserialization.py\u001b[0m in \u001b[0;36mload_function_def_library\u001b[0;34m(library, load_shared_name_suffix, wrapper_function)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;31m# import).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m       \u001b[0mfunc_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction_def_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_def_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m     \u001b[0;31m# Restores gradients for function-call ops (not the same as ops that use\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0;31m# custom gradients)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/framework/function_def_to_graph.py\u001b[0m in \u001b[0;36mfunction_def_to_graph\u001b[0;34m(fdef, input_shapes)\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mfunc_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# Add all function nodes to the graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mimporter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_graph_def_for_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# Initialize fields specific to FuncGraph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/framework/importer.py\u001b[0m in \u001b[0;36mimport_graph_def_for_function\u001b[0;34m(graph_def, name)\u001b[0m\n\u001b[1;32m    416\u001b[0m     graph_def, name=None):\n\u001b[1;32m    417\u001b[0m   \u001b[0;34m\"\"\"Like import_graph_def but does not validate colocation constraints.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m   return _import_graph_def_internal(\n\u001b[0m\u001b[1;32m    419\u001b[0m       graph_def, validate_colocation_constraints=False, name=name)\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/framework/importer.py\u001b[0m in \u001b[0;36m_import_graph_def_internal\u001b[0;34m(graph_def, input_map, return_elements, validate_colocation_constraints, name, producer_op_list)\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;31m# TODO(skyewm): avoid sending serialized FunctionDefs back to the TF_Graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m     \u001b[0m_ProcessNewOps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlibrary\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/framework/importer.py\u001b[0m in \u001b[0;36m_ProcessNewOps\u001b[0;34m(graph)\u001b[0m\n\u001b[1;32m    249\u001b[0m   \u001b[0mcolocation_pairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mnew_op\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_new_tf_operations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_devices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0moriginal_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0mnew_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_add_new_tf_operations\u001b[0;34m(self, compute_devices)\u001b[0m\n\u001b[1;32m   3845\u001b[0m     \u001b[0;31m# Create all Operation objects before accessing their inputs since an op may\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3846\u001b[0m     \u001b[0;31m# be created before its inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3847\u001b[0;31m     new_ops = [\n\u001b[0m\u001b[1;32m   3848\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_from_tf_operation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_devices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3849\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mc_op\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_tf_operations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3846\u001b[0m     \u001b[0;31m# be created before its inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3847\u001b[0m     new_ops = [\n\u001b[0;32m-> 3848\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_from_tf_operation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_devices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3849\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mc_op\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_tf_operations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3850\u001b[0m     ]\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_from_tf_operation\u001b[0;34m(self, c_op, compute_device)\u001b[0m\n\u001b[1;32m   3728\u001b[0m     \"\"\"\n\u001b[1;32m   3729\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_not_finalized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3730\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3731\u001b[0m     \u001b[0;31m# If a name_scope was created with ret.name but no nodes were created in it,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3732\u001b[0m     \u001b[0;31m# the name will still appear in _names_in_use even though the name hasn't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   2099\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_traceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_stack_for_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2103\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/util/tf_stack.py\u001b[0m in \u001b[0;36mextract_stack_for_node\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    191\u001b[0m   \u001b[0;31m# traversing the stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m   \u001b[0mthread_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_thread_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m   return _tf_stack.extract_stack_for_node(\n\u001b[0m\u001b[1;32m    194\u001b[0m       \u001b[0m_source_mapper_stacks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mthread_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m       _source_filter_stacks[thread_key][-1].internal_set, node)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model, tokenizer_word_index, MAX_SEQ_LEN = load_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get test data from ./SQUAD MATERIAL/test_set.json\n"
     ]
    }
   ],
   "source": [
    "context, question, df = get_test_data(test_path, tokenizer_word_index, MAX_SEQ_LEN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questionID</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "      <td>architecturally, the school has a catholic cha...</td>\n",
       "      <td>to whom did the virgin mary allegedly appear i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5733be284776f4190066117f</td>\n",
       "      <td>architecturally, the school has a catholic cha...</td>\n",
       "      <td>what is in front of the notre dame main building?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5733be284776f41900661180</td>\n",
       "      <td>architecturally, the school has a catholic cha...</td>\n",
       "      <td>the basilica of the sacred heart at notre dame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5733be284776f41900661181</td>\n",
       "      <td>architecturally, the school has a catholic cha...</td>\n",
       "      <td>what is the grotto at notre dame?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5733be284776f4190066117e</td>\n",
       "      <td>architecturally, the school has a catholic cha...</td>\n",
       "      <td>what sits on top of the main building at notre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>573410864776f419006617e5</td>\n",
       "      <td>other authors have focused on the structural c...</td>\n",
       "      <td>in the build-up to genocide, what have other a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>573410864776f419006617e6</td>\n",
       "      <td>other authors have focused on the structural c...</td>\n",
       "      <td>what processes are thought to create an evolut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>573410864776f419006617e7</td>\n",
       "      <td>other authors have focused on the structural c...</td>\n",
       "      <td>who revealed the starting points of this evolu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>573410864776f419006617e8</td>\n",
       "      <td>other authors have focused on the structural c...</td>\n",
       "      <td>a history of what is just one factor that cont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>573410864776f419006617e9</td>\n",
       "      <td>other authors have focused on the structural c...</td>\n",
       "      <td>what is one preventive effort in circumventing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1314 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    questionID  \\\n",
       "0     5733be284776f41900661182   \n",
       "1     5733be284776f4190066117f   \n",
       "2     5733be284776f41900661180   \n",
       "3     5733be284776f41900661181   \n",
       "4     5733be284776f4190066117e   \n",
       "...                        ...   \n",
       "1309  573410864776f419006617e5   \n",
       "1310  573410864776f419006617e6   \n",
       "1311  573410864776f419006617e7   \n",
       "1312  573410864776f419006617e8   \n",
       "1313  573410864776f419006617e9   \n",
       "\n",
       "                                                context  \\\n",
       "0     architecturally, the school has a catholic cha...   \n",
       "1     architecturally, the school has a catholic cha...   \n",
       "2     architecturally, the school has a catholic cha...   \n",
       "3     architecturally, the school has a catholic cha...   \n",
       "4     architecturally, the school has a catholic cha...   \n",
       "...                                                 ...   \n",
       "1309  other authors have focused on the structural c...   \n",
       "1310  other authors have focused on the structural c...   \n",
       "1311  other authors have focused on the structural c...   \n",
       "1312  other authors have focused on the structural c...   \n",
       "1313  other authors have focused on the structural c...   \n",
       "\n",
       "                                               question  \n",
       "0     to whom did the virgin mary allegedly appear i...  \n",
       "1     what is in front of the notre dame main building?  \n",
       "2     the basilica of the sacred heart at notre dame...  \n",
       "3                     what is the grotto at notre dame?  \n",
       "4     what sits on top of the main building at notre...  \n",
       "...                                                 ...  \n",
       "1309  in the build-up to genocide, what have other a...  \n",
       "1310  what processes are thought to create an evolut...  \n",
       "1311  who revealed the starting points of this evolu...  \n",
       "1312  a history of what is just one factor that cont...  \n",
       "1313  what is one preventive effort in circumventing...  \n",
       "\n",
       "[1314 rows x 3 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get predicitons..\n",
      "Gotten the predcitions!\n"
     ]
    }
   ],
   "source": [
    "pred_start, pred_end = get_predicitons(model, context, question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert predicitons to answer text..\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 38\n",
      "len 114\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 170\n",
      "len 219\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta -1\n",
      "len 97\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta -1\n",
      "len 97\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 68\n",
      "len 97\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 33\n",
      "len 159\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 24\n",
      "len 190\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 89\n",
      "len 190\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 24\n",
      "len 190\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 135\n",
      "len 190\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta -1\n",
      "len 157\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta -1\n",
      "len 86\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta -1\n",
      "len 86\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 57\n",
      "len 139\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 61\n",
      "len 139\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 82\n",
      "len 139\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 147\n",
      "len 190\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 81\n",
      "len 165\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 45\n",
      "len 131\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 167\n",
      "len 255\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 20\n",
      "len 216\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 44\n",
      "len 163\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 44\n",
      "len 163\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 274\n",
      "len 280\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta -1\n",
      "len 88\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 20\n",
      "len 88\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta -1\n",
      "len 95\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta -1\n",
      "len 116\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta -1\n",
      "len 86\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 11\n",
      "len 125\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 72\n",
      "len 179\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 70\n",
      "len 94\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 15\n",
      "len 147\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 80\n",
      "len 149\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta -1\n",
      "len 233\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta -1\n",
      "len 122\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta -1\n",
      "len 122\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta -1\n",
      "len 122\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta -1\n",
      "len 122\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 143\n",
      "len 295\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 73\n",
      "len 128\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 42\n",
      "len 187\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 42\n",
      "len 109\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 82\n",
      "len 109\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta -1\n",
      "len 109\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 84\n",
      "len 109\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 83\n",
      "len 109\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 87\n",
      "len 160\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 164\n",
      "len 176\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 117\n",
      "len 176\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 49\n",
      "len 93\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 23\n",
      "len 93\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta -1\n",
      "len 124\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 22\n",
      "len 124\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 61\n",
      "len 124\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 49\n",
      "len 228\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 94\n",
      "len 228\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 49\n",
      "len 228\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 39\n",
      "len 239\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 220\n",
      "len 239\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 220\n",
      "len 239\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 53\n",
      "len 134\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 177\n",
      "len 184\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 109\n",
      "len 143\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 45\n",
      "len 143\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 24\n",
      "len 181\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 126\n",
      "len 181\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 57\n",
      "len 150\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 76\n",
      "len 312\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 171\n",
      "len 178\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta -1\n",
      "len 67\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta -1\n",
      "len 67\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta -1\n",
      "len 67\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 59\n",
      "len 100\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 98\n",
      "len 157\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 94\n",
      "len 197\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 110\n",
      "len 197\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 213\n",
      "len 264\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 230\n",
      "len 264\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 50\n",
      "len 188\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 127\n",
      "len 188\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 68\n",
      "len 188\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 18\n",
      "len 188\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 102\n",
      "len 160\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 17\n",
      "len 151\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 62\n",
      "len 151\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 36\n",
      "len 151\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 64\n",
      "len 101\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 20\n",
      "len 77\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 20\n",
      "len 77\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 66\n",
      "len 77\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 20\n",
      "len 77\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 12\n",
      "len 77\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 273\n",
      "len 326\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 53\n",
      "len 326\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta -1\n",
      "len 326\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 284\n",
      "len 326\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 97\n",
      "len 326\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 14\n",
      "len 326\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 3\n",
      "len 79\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 49\n",
      "len 97\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 111\n",
      "len 140\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 103\n",
      "len 140\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 72\n",
      "len 140\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 105\n",
      "len 140\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 84\n",
      "len 127\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 90\n",
      "len 127\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 11\n",
      "len 127\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 58\n",
      "len 127\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 17\n",
      "len 114\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 67\n",
      "len 114\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 35\n",
      "len 95\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 49\n",
      "len 95\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 35\n",
      "len 105\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 35\n",
      "len 105\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 20\n",
      "len 129\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 82\n",
      "len 129\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 21\n",
      "len 99\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 36\n",
      "len 98\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 9\n",
      "len 98\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta -1\n",
      "len 59\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta -1\n",
      "len 59\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 40\n",
      "len 81\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta -1\n",
      "len 99\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 91\n",
      "len 99\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 73\n",
      "len 96\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta -1\n",
      "len 96\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 50\n",
      "len 96\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 18\n",
      "len 229\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 90\n",
      "len 198\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta -1\n",
      "len 198\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 20\n",
      "len 198\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 35\n",
      "len 193\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 41\n",
      "len 98\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 41\n",
      "len 98\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 94\n",
      "len 125\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 27\n",
      "len 148\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 43\n",
      "len 148\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 116\n",
      "len 148\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 88\n",
      "len 128\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta -1\n",
      "len 128\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta -1\n",
      "len 128\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 59\n",
      "len 135\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 23\n",
      "len 50\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 63\n",
      "len 149\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 45\n",
      "len 286\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 274\n",
      "len 286\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 53\n",
      "len 286\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta -1\n",
      "len 103\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta -1\n",
      "len 103\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 112\n",
      "len 151\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 159\n",
      "len 170\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta -1\n",
      "len 160\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta -1\n",
      "len 67\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 54\n",
      "len 112\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 85\n",
      "len 112\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 104\n",
      "len 129\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 180\n",
      "len 341\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 285\n",
      "len 341\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 169\n",
      "len 341\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 27\n",
      "len 136\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 21\n",
      "len 101\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta -1\n",
      "len 211\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 39\n",
      "len 195\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 64\n",
      "len 195\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 96\n",
      "len 195\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 134\n",
      "len 142\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 71\n",
      "len 151\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 14\n",
      "len 237\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 22\n",
      "len 92\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 18\n",
      "len 109\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 18\n",
      "len 109\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 25\n",
      "len 112\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 24\n",
      "len 112\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 103\n",
      "len 155\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta -1\n",
      "len 155\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 102\n",
      "len 120\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 84\n",
      "len 120\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 36\n",
      "len 182\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 26\n",
      "len 157\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 106\n",
      "len 157\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 102\n",
      "len 122\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta -1\n",
      "len 130\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 56\n",
      "len 130\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 56\n",
      "len 120\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 64\n",
      "len 125\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 64\n",
      "len 165\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 79\n",
      "len 144\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 90\n",
      "len 144\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta -1\n",
      "len 138\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta -1\n",
      "len 94\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 31\n",
      "len 94\n",
      "\n",
      "\n",
      "SOMETHING STRANGE IS GOING ON AND END PRED IS BEFORE START PRED\n",
      "\n",
      "\n",
      "satrta 16\n",
      "len 178\n"
     ]
    }
   ],
   "source": [
    "answer_dict = make_answer_dict(pred_start, pred_end, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving answer to predictions.txt\n"
     ]
    }
   ],
   "source": [
    "write_predictions(answer_dict, prediction_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SQUAD MATERIAL/test_set.json') as f:\n",
    "    dataset_json = json.load(f)\n",
    "dataset = dataset_json['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
